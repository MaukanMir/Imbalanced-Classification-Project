{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This section will focus on creating Cost sensative Learning on imbalanced datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.985\n"
     ]
    }
   ],
   "source": [
    "# fit a logistic regression model on an imbalanced classification dataset\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n",
    "# define model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1) # summarize performance\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Logistic Regression with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The LogisticRegression class provides the class weight argument that can be specified as a model hyperparameter. The class weight is a dictionary that defines each class label (e.g. 0 and 1) and the weighting to apply in the calculation of the negative log likelihood when fitting the model. For example, a 1 to 1 weighting for each class 0 and 1 can be defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.989\n"
     ]
    }
   ],
   "source": [
    "# weighted logistic regression model on an imbalanced classification dataset\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n",
    "# define model\n",
    "weights = {0:0.01, 1:1.0}\n",
    "model = LogisticRegression(solver='lbfgs', class_weight=weights)\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1) # summarize performance\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The scikit-learn library provides an implementation of the best practice heuristic for the class weighting. It is implemented via the compute class weight() function and is calculated as:\n",
    "\n",
    "#### n_samples/ n_classes * n_samples_with_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 0.5050505050505051, 1: 50.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate a 2-class dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0, \n",
    "                           n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n",
    "\n",
    "# Dynamically identify classes\n",
    "classes = np.unique(y)\n",
    "\n",
    "# Calculate class weighting\n",
    "weight = class_weight.compute_class_weight('balanced', classes=classes, y=y)\n",
    "\n",
    "# Create a dictionary mapping class labels to weights\n",
    "class_weights = dict(zip(classes, weight))\n",
    "\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.989\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# weighted logistic regression for class imbalance with heuristic weights\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n",
    "# define model\n",
    "model = LogisticRegression(solver='lbfgs', class_weight='balanced')\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1) # summarize performance\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Weighted Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.988943 using {'class_weight': {0: 1, 1: 100}}\n",
      "0.982148 (0.017020) with: {'class_weight': {0: 100, 1: 1}}\n",
      "0.983465 (0.015555) with: {'class_weight': {0: 10, 1: 1}}\n",
      "0.985242 (0.013456) with: {'class_weight': {0: 1, 1: 1}}\n",
      "0.987973 (0.009846) with: {'class_weight': {0: 1, 1: 10}}\n",
      "0.988943 (0.006354) with: {'class_weight': {0: 1, 1: 100}}\n"
     ]
    }
   ],
   "source": [
    "# grid search class weights with logistic regression for imbalanced classification\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n",
    "# define model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "# define grid\n",
    "balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}] \n",
    "param_grid = dict(class_weight=balance)\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv,\n",
    "scoring='roc_auc')\n",
    "# execute the grid search\n",
    "grid_result = grid.fit(X, y)\n",
    "# report the best configuration\n",
    "print('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_)) # report all configurations\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('%f (%f) with: %r' % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost-Sensative Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
