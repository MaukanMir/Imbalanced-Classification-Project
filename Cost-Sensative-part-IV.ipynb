{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This section will focus on creating Cost sensative Learning on imbalanced datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.985\n"
     ]
    }
   ],
   "source": [
    "# fit a logistic regression model on an imbalanced classification dataset\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n",
    "# define model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1) # summarize performance\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Logistic Regression with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The LogisticRegression class provides the class weight argument that can be specified as a model hyperparameter. The class weight is a dictionary that defines each class label (e.g. 0 and 1) and the weighting to apply in the calculation of the negative log likelihood when fitting the model. For example, a 1 to 1 weighting for each class 0 and 1 can be defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.989\n"
     ]
    }
   ],
   "source": [
    "# weighted logistic regression model on an imbalanced classification dataset\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n",
    "# define model\n",
    "weights = {0:0.01, 1:1.0}\n",
    "model = LogisticRegression(solver='lbfgs', class_weight=weights)\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1) # summarize performance\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The scikit-learn library provides an implementation of the best practice heuristic for the class weighting. It is implemented via the compute class weight() function and is calculated as:\n",
    "\n",
    "#### n_samples/ n_classes * n_samples_with_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 0.5050505050505051, 1: 50.0}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate a 2-class dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0, \n",
    "                           n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n",
    "\n",
    "# Dynamically identify classes\n",
    "classes = np.unique(y)\n",
    "\n",
    "# Calculate class weighting\n",
    "weight = class_weight.compute_class_weight('balanced', classes=classes, y=y)\n",
    "\n",
    "# Create a dictionary mapping class labels to weights\n",
    "class_weights = dict(zip(classes, weight))\n",
    "\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.989\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# weighted logistic regression for class imbalance with heuristic weights\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n",
    "# define model\n",
    "model = LogisticRegression(solver='lbfgs', class_weight='balanced')\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1) # summarize performance\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Weighted Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.988943 using {'class_weight': {0: 1, 1: 100}}\n",
      "0.982148 (0.017020) with: {'class_weight': {0: 100, 1: 1}}\n",
      "0.983465 (0.015555) with: {'class_weight': {0: 10, 1: 1}}\n",
      "0.985242 (0.013456) with: {'class_weight': {0: 1, 1: 1}}\n",
      "0.987973 (0.009846) with: {'class_weight': {0: 1, 1: 10}}\n",
      "0.988943 (0.006354) with: {'class_weight': {0: 1, 1: 100}}\n"
     ]
    }
   ],
   "source": [
    "# grid search class weights with logistic regression for imbalanced classification\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=2)\n",
    "# define model\n",
    "model = LogisticRegression(solver='lbfgs')\n",
    "# define grid\n",
    "balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}] \n",
    "param_grid = dict(class_weight=balance)\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv,\n",
    "scoring='roc_auc')\n",
    "# execute the grid search\n",
    "grid_result = grid.fit(X, y)\n",
    "# report the best configuration\n",
    "print('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_)) # report all configurations\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('%f (%f) with: %r' % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost-Sensative Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.755892 using {'class_weight': {0: 1, 1: 10}}\n",
      "0.740488 (0.079039) with: {'class_weight': {0: 100, 1: 1}}\n",
      "0.735690 (0.072483) with: {'class_weight': {0: 10, 1: 1}}\n",
      "0.735623 (0.070122) with: {'class_weight': {0: 1, 1: 1}}\n",
      "0.755892 (0.075222) with: {'class_weight': {0: 1, 1: 10}}\n",
      "0.747609 (0.070646) with: {'class_weight': {0: 1, 1: 100}}\n"
     ]
    }
   ],
   "source": [
    "# grid search class weights with decision tree for imbalance classification\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=3)\n",
    "# define model\n",
    "model = DecisionTreeClassifier()\n",
    "# define grid\n",
    "balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}]\n",
    "param_grid = dict(class_weight=balance)\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n",
    "# execute the grid search\n",
    "grid_result = grid.fit(X, y)\n",
    "# report the best configuration\n",
    "print('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_)) # report all configurations\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('%f (%f) with: %r' % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost-Sensitive Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing SVM model on an imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.808\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# fit a svm on an imbalanced classification dataset\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=4)\n",
    "# define model\n",
    "model = SVC(gamma='scale')\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1) # summarize performance\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with Class Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC: 0.967\n"
     ]
    }
   ],
   "source": [
    "# svm with class weight on an imbalanced classification dataset\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=4)\n",
    "# define model\n",
    "model = SVC(gamma='scale', class_weight='balanced')\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv, n_jobs=-1) # summarize performance\n",
    "print('Mean ROC AUC: %.3f' % mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Class Weight SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.967747 using {'class_weight': {0: 1, 1: 100}}\n",
      "0.742936 (0.149898) with: {'class_weight': {0: 100, 1: 1}}\n",
      "0.748636 (0.149871) with: {'class_weight': {0: 10, 1: 1}}\n",
      "0.807963 (0.126343) with: {'class_weight': {0: 1, 1: 1}}\n",
      "0.934495 (0.065221) with: {'class_weight': {0: 1, 1: 10}}\n",
      "0.967747 (0.038636) with: {'class_weight': {0: 1, 1: 100}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# grid search class weights with svm for imbalance classification\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "# generate dataset\n",
    "X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "    n_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=4)\n",
    "# define model\n",
    "model = SVC(gamma='scale')\n",
    "# define grid\n",
    "balance = [{0:100,1:1}, {0:10,1:1}, {0:1,1:1}, {0:1,1:10}, {0:1,1:100}] \n",
    "param_grid = dict(class_weight=balance)\n",
    "# define evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# define grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=cv, scoring='roc_auc')\n",
    "# execute the grid search\n",
    "grid_result = grid.fit(X, y)\n",
    "# report the best configuration\n",
    "print('Best: %f using %s' % (grid_result.best_score_, grid_result.best_params_)) # report all configurations\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('%f (%f) with: %r' % (mean, stdev, param))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost-Sensitive Deep Learning in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 17:34:29.197654: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 261us/step\n",
      "ROC AUC: 0.931\n"
     ]
    }
   ],
   "source": [
    "# standard neural network on an imbalanced classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "# prepare train and test dataset\n",
    "def prepare_data():\n",
    "  # generate 2d classification dataset\n",
    "  X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "      n_clusters_per_class=2, weights=[0.99], flip_y=0, random_state=4)\n",
    "  # split into train and test\n",
    "  n_train = 5000\n",
    "  trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "  trainy, testy = y[:n_train], y[n_train:]\n",
    "  return trainX, trainy, testX, testy\n",
    "# define the neural network model\n",
    "def define_model(n_input):\n",
    "  # define model\n",
    "  model = Sequential()\n",
    "  # define first hidden layer and visible layer \n",
    "  model.add(Dense(10, input_dim=n_input, activation='relu',\n",
    "  kernel_initializer='he_uniform'))\n",
    "  # define output layer\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  # define loss and optimizer \n",
    "  model.compile(loss='binary_crossentropy', optimizer='sgd') \n",
    "  return model\n",
    "# prepare dataset\n",
    "trainX, trainy, testX, testy = prepare_data()\n",
    "# define the model\n",
    "n_input = trainX.shape[1]\n",
    "model = define_model(n_input)\n",
    "# fit model\n",
    "model.fit(trainX, trainy, epochs=100, verbose=0) # make predictions on the test dataset\n",
    "yhat = model.predict(testX)\n",
    "# evaluate the ROC AUC of the predictions\n",
    "score = roc_auc_score(testy, yhat)\n",
    "print('ROC AUC: %.3f' % score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Weighting with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 253us/step\n",
      "ROC AUC: 0.971\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# class weighted neural network on an imbalanced classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "# prepare train and test dataset\n",
    "def prepare_data():\n",
    "  # generate 2d classification dataset\n",
    "  X, y = make_classification(n_samples=10000, n_features=2, n_redundant=0,\n",
    "      n_clusters_per_class=2, weights=[0.99], flip_y=0, random_state=4)\n",
    "  # split into train and test\n",
    "  n_train = 5000\n",
    "  trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "  trainy, testy = y[:n_train], y[n_train:]\n",
    "  return trainX, trainy, testX, testy\n",
    "\n",
    "# define the neural network model\n",
    "def define_model(n_input):\n",
    "  # define model\n",
    "  model = Sequential()\n",
    "  # define first hidden layer and visible layer \n",
    "  model.add(Dense(10, input_dim=n_input, activation='relu',\n",
    "  kernel_initializer='he_uniform'))\n",
    "  # define output layer\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  # define loss and optimizer \n",
    "  model.compile(loss='binary_crossentropy', optimizer='sgd') \n",
    "  return model\n",
    "\n",
    "# prepare dataset\n",
    "trainX, trainy, testX, testy = prepare_data()\n",
    "# get the model\n",
    "\n",
    "n_input = trainX.shape[1]\n",
    "model = define_model(n_input)\n",
    "# fit model\n",
    "weights = {0:1, 1:100}\n",
    "history = model.fit(trainX, trainy, class_weight=weights, epochs=100, verbose=0) # evaluate model\n",
    "yhat = model.predict(testX)\n",
    "score = roc_auc_score(testy, yhat)\n",
    "print('ROC AUC: %.3f' % score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
