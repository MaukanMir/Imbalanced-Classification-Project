{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Framework for Imbalanced Classification Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The shortest path to a good result on a new classification task is to systematically evaluate a suite of machine learning algorithms in order to discover what works well, then double down on what works well. This approach can also be used for imbalanced classification problems, tailored for the range of data sampling, cost-sensitive, and one-class classification algorithms that one may choose from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Select a Metric\n",
    "### 2. Spot-Check Algorithms\n",
    "### 3. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) selecting a metric by which to evaluate candidate models\n",
    "### (2) testing a suite of algorithms\n",
    "### (3) tuning the best performing models. This may not be the only approach; it is just the simplest reliable process to get you from I have a new dataset to I have good results very quickly. This process can be summarized as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a Metric\n",
    "### Spot-Check Algorithms\n",
    "### Spot-Check Imbalanced Algorithms \n",
    "### Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Are you predicting probabilities? \n",
    "#### – Do you need class labels?\n",
    "#### Is the positive class more important? = Use Precision-Recall AUC\n",
    "#### Are both classes important? = Use ROC AUC\n",
    "#### – Do you need probabilities?\n",
    "#### Use Brier Score and Brier Skill Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you predicting class labels? If so, consider the following:\n",
    "- **Is the positive class more important?**\n",
    "  - *If False Negatives and False Positives are equally important*, use the **F1-Measure**.\n",
    "  - *If False Negatives are more important*, use the **F2-measure**.\n",
    "  - *If False Positives are more important*, use the **F0.5-measure**.\n",
    "- **Are both classes important?**\n",
    "  - *If you have less than 80%-90% of examples for the majority class*, **Accuracy** is a suitable metric.\n",
    "  - *If you have more than 80%-90% of examples for the majority class*, the **G-mean** is recommended.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot-Check Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spot-checking machine learning algorithms means evaluating a suite of different types of algorithms with minimal hyperparameter tuning. Specifically, it means giving each algorithm a good chance to learn about the problem, including performing any required data preparation expected by the algorithm and using best-practice configuration options or defaults. The objective is to quickly test a range of standard machine learning algorithms and provide a baseline in performance to which techniques specialized for imbalanced classification must be compared and outperform in order to be considered skillful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A robust test harness must be defined for effective model evaluation. This often involves using **k-fold cross-validation**, with k = 10 being a sensible default. It's important to use **Stratified cross-validation** to ensure that each fold maintains the same class distribution as the original dataset. Additionally, repeating the cross-validation procedure multiple times, such as 3, 10, or 30 times, can effectively capture a sample of model performance on the dataset. The results are usually summarized with a mean and standard deviation of the scores.\n",
    "\n",
    "When it comes to spot-checking algorithms, there are perhaps four levels to consider:\n",
    "1. **Naive Algorithms**: Basic approaches that can provide a baseline for performance.\n",
    "2. **Linear Algorithms**: These include methods like Logistic Regression and Linear SVC which are effective when there is a linear relationship in the data.\n",
    "3. **Nonlinear Algorithms**: These are algorithms that can capture complex patterns in data, like Decision Trees and Kernel SVMs.\n",
    "4. **Ensemble Algorithms**: These methods combine predictions from multiple models to improve overall performance, such as Random Forests and Gradient Boosting Machines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sampling Tecnhiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data oversampling involves duplicating examples of the minority class or synthesizing new examples from the minority class from existing examples. Perhaps the most popular methods are **SMOTE** and variations such as **Borderline SMOTE**. Perhaps the most important hyperparameter to tune is the amount of oversampling to perform. Examples of data oversampling methods include:\n",
    "- **Random Oversampling**\n",
    "- **SMOTE**\n",
    "- **Borderline SMOTE**\n",
    "- **SVM SMOTE**\n",
    "- **k-Means SMOTE**\n",
    "- **ADASYN**\n",
    "\n",
    "Undersampling involves deleting examples from the majority class, such as randomly or using an algorithm to carefully choose which examples to delete. Popular editing algorithms include the edited nearest neighbors and Tomek links. Examples of data undersampling methods include:\n",
    "- **Random Undersampling**\n",
    "- **Condensed Nearest Neighbor**\n",
    "- **Tomek Links**\n",
    "- **Edited Nearest Neighbors**\n",
    "- **Neighborhood Cleaning Rule**\n",
    "- **One-Sided Selection**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost any oversampling method can be combined with almost any undersampling technique. Therefore, it may be beneficial to test a suite of different combinations of oversampling and undersampling techniques. Examples of popular combinations of over and undersampling include:\n",
    "- **SMOTE and Random Undersampling**\n",
    "- **SMOTE and Tomek Links**\n",
    "- **SMOTE and Edited Nearest Neighbors**\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
